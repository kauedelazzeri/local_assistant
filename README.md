# InsightFinder â€” Busca Inteligente por Arquivos Locais

Uma aplicaÃ§Ã£o local que permite buscar informaÃ§Ãµes em linguagem natural dentro de arquivos do seu computador, funcionando como um "Copilot pessoal" para seus arquivos.

## ğŸš€ Funcionalidades

- Busca em linguagem natural
- Suporte a mÃºltiplos formatos de arquivo (TXT, PDF, PPTX, XLSX, JPG, PNG)
- Processamento local com IA via Ollama
- Interface web amigÃ¡vel
- Privacidade total (tudo roda localmente)

## ğŸ“‹ PrÃ©-requisitos

- Python 3.8+
- Node.js 16+ (para o frontend)
- Ollama instalado e rodando localmente
- Tesseract OCR instalado (para processamento de imagens)

## ğŸ› ï¸ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/insight-finder.git
cd insight-finder
```

2. Instale as dependÃªncias do backend:
```bash
pip install -r requirements.txt
```

3. Instale as dependÃªncias do frontend:
```bash
cd frontend
npm install
```

## âš™ï¸ Como usar IA local com Ollama

1. Baixe e instale o [Ollama](https://ollama.com/download).
2. ApÃ³s instalar, rode no terminal:
```bash
ollama run llama2
```
3. Para usar outro modelo, como `phi`, `mistral`, ou `llava`, execute:
```bash
ollama run nome-do-modelo
```
4. Para trocar o modelo padrÃ£o no cÃ³digo, edite o arquivo:
```bash
backend/main.py
```
E altere a linha:
```python
OLLAMA_MODEL = "llama2"
```

## ğŸš€ Executando

1. Inicie o backend:
```bash
python backend/main.py
```

2. Em outro terminal, inicie o frontend:
```bash
cd frontend
npm start
```
2. Em outro terminal, inicie o servidor llama2:
```bash
ollama serve
```

4. Acesse a aplicaÃ§Ã£o em `http://localhost:3000`

## ğŸ“ Estrutura do Projeto

```
insight-finder/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ services/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ“‚ Caminho padrÃ£o de busca

O projeto tenta automaticamente definir a pasta padrÃ£o de busca como a pasta de Downloads do sistema (Windows). O campo pode ser editado manualmente na interface.

## ğŸ”’ Privacidade

- Todo o processamento Ã© feito localmente
- Nenhum dado Ã© enviado para a internet
- Os arquivos sÃ£o indexados apenas nas pastas autorizadas

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.
